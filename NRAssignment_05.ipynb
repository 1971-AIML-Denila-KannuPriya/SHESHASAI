{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82d8b15c-1f67-4882-b4bf-84ed9c3dafe0",
   "metadata": {},
   "source": [
    "## 1. Implement a K-Nearest Neighbors (KNN) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e65eecc8-8d63-456e-a0cc-905ee9c50c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label predicted for the new point using KNN: B\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from math import sqrt\n",
    "\n",
    "def knn_classifier(data_points, new_point, k=3):\n",
    "    distances = []\n",
    "    for point in data_points:\n",
    "        distance = sqrt((point[0] - new_point[0]) ** 2 + (point[1] - new_point[1]) ** 2)\n",
    "        distances.append((distance, point[2]))\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    nearest_neighbors = [label for _, label in distances[:k]]\n",
    "    most_common = Counter(nearest_neighbors).most_common(1)\n",
    "    return most_common[0][0]\n",
    "    \n",
    "data = [(2, 4, 'A'), (3, 5, 'B'), (5, 3, 'A'), (8, 8, 'B'), (9, 7, 'B')]\n",
    "new_data_point = (6, 6)\n",
    "result = knn_classifier(data, new_data_point)\n",
    "print(\"label predicted for the new point using KNN:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633e0bf4-35aa-436b-807d-473b7a87670a",
   "metadata": {},
   "source": [
    "## 2. Remove Outliers from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2cd9d09-d65c-4abc-9d98-966a8f6999ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new list without the outliers: [9, 11, 14, 18, 21, 26, 29, 34, 37]\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "def remove_outliers(data):\n",
    "    q1 = statistics.median_low(data[:len(data)//2])\n",
    "    q3 = statistics.median_high(data[len(data)//2:])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    return [x for x in data if lower_bound <= x <= upper_bound]\n",
    "data = [9, 11, 14, 18, 21, 26, 450, 29, 34, 37]\n",
    "cleaned_data = remove_outliers(data)\n",
    "print(\"new list without the outliers:\",cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9773b4-e817-4f24-be80-ab473ffd7cfc",
   "metadata": {},
   "source": [
    "##  3. Optimize a Matrix Multiplication for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d30d487-434b-4b45-a87e-1741c7c58150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Output is [[48, 43], [27, 23], [37, 37]]\n"
     ]
    }
   ],
   "source": [
    "def matrix_multiply(mat1, mat2):\n",
    "    rows_mat1 = len(mat1)\n",
    "    cols_mat1 = len(mat1[0])\n",
    "    rows_mat2 = len(mat2)\n",
    "    cols_mat2 = len(mat2[0])\n",
    "\n",
    "    if cols_mat1 != rows_mat2:\n",
    "        return \"Incompatible matrices for multiplication\"\n",
    "\n",
    "    result = [[sum(mat1[i][k] * mat2[k][j] for k in range(cols_mat1)) for j in range(cols_mat2)] for i in range(rows_mat1)]\n",
    "    return result\n",
    "\n",
    "mat1 = [[2, 3, 4], [1, 0, 5], [3, 2, 1]]\n",
    "mat2 = [[7, 8], [6, 5], [4, 3]]\n",
    "result = matrix_multiply(mat1, mat2)\n",
    "print(\"The Output is\",result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31079166-d04b-487d-8707-335f1b0c8831",
   "metadata": {},
   "source": [
    "## 4. Word Embedding Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7120fb27-e310-4cfd-af84-eea1e10aa692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Output is: 0.9746318461970762\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = sum(v1 * v2 for v1, v2 in zip(vec1, vec2))\n",
    "    magnitude_vec1 = math.sqrt(sum(v1 ** 2 for v1 in vec1))\n",
    "    magnitude_vec2 = math.sqrt(sum(v2 ** 2 for v2 in vec2))\n",
    "    return dot_product / (magnitude_vec1 * magnitude_vec2)\n",
    "vec1 = [1.0, 2.0, 3.0]\n",
    "vec2 = [4.0, 5.0, 6.0]\n",
    "similarity = cosine_similarity(vec1, vec2)\n",
    "print(\"The Output is:\",similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e7a699-c138-4740-98da-3b73fd3b399f",
   "metadata": {},
   "source": [
    "##  5. Implement a Min-Heap Using a Priority Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d73ce667-960f-448d-9714-8138a3515888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Min Heap: [3, 8, 20, 15, 25]\n",
      "3\n",
      "3\n",
      "Current Min Heap: [8, 15, 20, 25]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "class MinHeap:\n",
    "    def __init__(self):\n",
    "        self.heap = []\n",
    "    def insert(self, *values):\n",
    "        for value in values:\n",
    "            heapq.heappush(self.heap, value)\n",
    "\n",
    "    def get_min(self):\n",
    "        return self.heap[0] if self.heap else None\n",
    "\n",
    "    def extract_min(self):\n",
    "        return heapq.heappop(self.heap) if self.heap else None\n",
    "\n",
    "    def print_heap(self):\n",
    "        print(\"Current Min Heap:\", self.heap)\n",
    "        \n",
    "min_heap = MinHeap()\n",
    "min_heap.insert(15, 3, 20, 8, 25)\n",
    "min_heap.print_heap() \n",
    "print(min_heap.get_min()) \n",
    "print(min_heap.extract_min())  \n",
    "min_heap.print_heap()  \n",
    "print(min_heap.get_min())   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ad573-5b77-4cea-bde8-f8debf4dd33b",
   "metadata": {},
   "source": [
    "## 6. Implement a Support Vector Machine (SVM) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ece9b76b-cbb5-4934-afef-70b6cde6c1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label predicted for the new point using SVM with a linear kernel: B\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def svm_classifier(data_points, new_point, kernel_type='linear'):\n",
    "    X = [(x, y) for x, y, label in data_points] \n",
    "    y = [label for _, _, label in data_points]   \n",
    "    clf = svm.SVC(kernel=kernel_type)\n",
    "    clf.fit(X, y) \n",
    "    return clf.predict([new_point])[0] \n",
    "\n",
    "data_points = [\n",
    "    (1.5, 2.5, 'A'), \n",
    "    (3.0, 4.0, 'A'), \n",
    "    (3.5, 1.0, 'B'), \n",
    "    (6.0, 7.5, 'B'), \n",
    "    (7.0, 8.0, 'A'), \n",
    "    (5.0, 6.0, 'B')\n",
    "]\n",
    "new_point = (4.0, 5.0) \n",
    "\n",
    "predicted_label = svm_classifier(data_points, new_point, kernel_type='linear')\n",
    "print(\"Label predicted for the new point using SVM with a linear kernel:\", predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199ebf9-f9e4-4522-aaa4-14452184b36d",
   "metadata": {},
   "source": [
    "##  7. Calculate the Z-Score of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82e71de6-2e24-4554-a80c-b4156b8671ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-scores for the new data: [-1.414213562373095, -0.7071067811865475, 0.0, 0.7071067811865475, 1.414213562373095]\n"
     ]
    }
   ],
   "source": [
    "def calculate_z_scores(data):\n",
    "    mean = sum(data) / len(data)\n",
    "    std_dev = (sum((x - mean) ** 2 for x in data) / len(data)) ** 0.5\n",
    "    return [(x - mean) / std_dev for x in data]\n",
    "\n",
    "data = [15, 25, 35, 45, 55]\n",
    "z_scores = calculate_z_scores(data)\n",
    "print(\"Z-scores for the new data:\", z_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1fbfb3-f511-4f92-a415-94653896a7e0",
   "metadata": {},
   "source": [
    "##  8. K-Means Clustering Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c8dfd65-6881-4033-ac9a-8f8b9c3ef6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final centroids: [(4.0, 6.0), (1.5, 2.5), (9.0, 10.5)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def euclidean_distance(p1, p2):\n",
    "    return ((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2) ** 0.5\n",
    "\n",
    "def assign_clusters(data_points, centroids):\n",
    "    clusters = [[] for _ in centroids]\n",
    "    for point in data_points:\n",
    "        distances = [euclidean_distance(point, centroid) for centroid in centroids]\n",
    "        closest_centroid = distances.index(min(distances))\n",
    "        clusters[closest_centroid].append(point)\n",
    "    return clusters\n",
    "\n",
    "def calculate_centroids(clusters):\n",
    "    centroids = []\n",
    "    for cluster in clusters:\n",
    "        if len(cluster) > 0:\n",
    "            x_coords = [p[0] for p in cluster]\n",
    "            y_coords = [p[1] for p in cluster]\n",
    "            centroids.append((sum(x_coords) / len(x_coords), sum(y_coords) / len(y_coords)))\n",
    "    return centroids\n",
    "\n",
    "def k_means_clustering(data_points, k):\n",
    "    centroids = random.sample(data_points, k)\n",
    "    for _ in range(100):  # Max iterations\n",
    "        clusters = assign_clusters(data_points, centroids)\n",
    "        new_centroids = calculate_centroids(clusters)\n",
    "        if new_centroids == centroids:\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    return centroids\n",
    "\n",
    "data_points = [(1, 2), (2, 3), (3, 5), (5, 7), (8, 9), (10, 12)]\n",
    "k = 3  \n",
    "centroids = k_means_clustering(data_points, k)\n",
    "print(\"Final centroids:\", centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b572807-2697-4c93-81c7-cdb082586e1b",
   "metadata": {},
   "source": [
    "##  9. Evaluate Classification Model Using F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec0eade1-8c19-476a-aa7a-e1a907fc8193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6\n"
     ]
    }
   ],
   "source": [
    "def f1_score(true_labels, predicted_labels):\n",
    "    tp = sum((t == 1 and p == 1) for t, p in zip(true_labels, predicted_labels))\n",
    "    fp = sum((t == 0 and p == 1) for t, p in zip(true_labels, predicted_labels))\n",
    "    fn = sum((t == 1 and p == 0) for t, p in zip(true_labels, predicted_labels))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "true_labels = [1, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n",
    "predicted_labels = [1, 0, 1, 0, 1, 0, 0, 1, 1, 0]\n",
    "\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5523abf-9ec9-4569-ba3d-8cd3cde63d6f",
   "metadata": {},
   "source": [
    "## 10. Visualize Data Distribution Using a Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bea8da9-1c6f-4245-96eb-26783db9c461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram: {'1.50 - 2.88': 3, '2.88 - 4.25': 3, '4.25 - 5.62': 2, '5.62 - 7.00': 1}\n"
     ]
    }
   ],
   "source": [
    "def create_histogram(data, bins):\n",
    "    min_value = min(data)\n",
    "    max_value = max(data)\n",
    "    bin_width = (max_value - min_value) / bins\n",
    "    histogram = {}\n",
    "    \n",
    "    for i in range(bins):\n",
    "        bin_start = min_value + i * bin_width\n",
    "        bin_end = bin_start + bin_width\n",
    "        count = sum(1 for x in data if bin_start <= x < bin_end)\n",
    "        histogram[f\"{bin_start:.2f} - {bin_end:.2f}\"] = count\n",
    "        \n",
    "    return histogram\n",
    "data = [1.5, 2.4, 2.9, 3.2, 4.5, 3.8, 2.7, 5.1, 6.3, 7.0]\n",
    "bins = 4\n",
    "histogram = create_histogram(data, bins)\n",
    "print(\"Histogram:\", histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb6abec-45a5-4fae-910e-e070bdf5091c",
   "metadata": {},
   "source": [
    "## 11. Implement a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e04f167-fa5b-4ff6-a12c-ff27634ca129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: B\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "def split(data, feature, threshold):\n",
    "    left = [point for point in data if point[0][feature] <= threshold]\n",
    "    right = [point for point in data if point[0][feature] > threshold]\n",
    "    return left, right\n",
    "\n",
    "def gini_index(data):\n",
    "    labels = [point[1] for point in data]\n",
    "    classes = set(labels)\n",
    "    total = len(labels)\n",
    "    gini = 1.0\n",
    "    for cls in classes:\n",
    "        prob = labels.count(cls) / total\n",
    "        gini -= prob ** 2\n",
    "    return gini\n",
    "\n",
    "def best_split(data):\n",
    "    best_gini = float('inf')\n",
    "    best_feature, best_threshold = None, None\n",
    "    for feature in range(len(data[0][0])):\n",
    "        thresholds = set(point[0][feature] for point in data)\n",
    "        for threshold in thresholds:\n",
    "            left, right = split(data, feature, threshold)\n",
    "            if left and right:\n",
    "                gini = (len(left) / len(data)) * gini_index(left) + (len(right) / len(data)) * gini_index(right)\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "    return best_feature, best_threshold\n",
    "\n",
    "def build_tree(data):\n",
    "    labels = [point[1] for point in data]\n",
    "    if len(set(labels)) == 1:\n",
    "        return Node(value=labels[0])\n",
    "    if not data:\n",
    "        return Node(value=max(set(labels), key=labels.count))\n",
    "\n",
    "    feature, threshold = best_split(data)\n",
    "    if feature is None:\n",
    "        return Node(value=max(set(labels), key=labels.count))\n",
    "\n",
    "    left_data, right_data = split(data, feature, threshold)\n",
    "    left_node = build_tree(left_data)\n",
    "    right_node = build_tree(right_data)\n",
    "    return Node(feature, threshold, left_node, right_node)\n",
    "\n",
    "def predict(tree, point):\n",
    "    if tree.value is not None:\n",
    "        return tree.value\n",
    "    if point[tree.feature] <= tree.threshold:\n",
    "        return predict(tree.left, point)\n",
    "    else:\n",
    "        return predict(tree.right, point)\n",
    "\n",
    "def decision_tree_classifier(data_points, new_point):\n",
    "    tree = build_tree(data_points)\n",
    "    return predict(tree, new_point)\n",
    "\n",
    "data_points = [([2.0, 3.0], 'A'), ([1.0, 1.0], 'B'), ([5.0, 4.0], 'A'), ([4.0, 2.0], 'B'),\n",
    "               ([3.0, 3.5], 'A'), ([3.5, 1.5], 'B')]\n",
    "new_point = [3.0, 2.0] \n",
    "\n",
    "label = decision_tree_classifier(data_points, new_point)\n",
    "print(\"Predicted label:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfb2835-c75e-4357-aac8-7f15ee0506f0",
   "metadata": {},
   "source": [
    "## 12. Normalize Data Using Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa12b1c0-edaa-421f-9368-1feef0712f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized values: [0.0, 0.25, 0.5, 0.75, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def min_max_normalization(data: List[float]) -> List[float]:\n",
    "    if not data:\n",
    "        return []\n",
    "    \n",
    "    min_value = min(data)\n",
    "    max_value = max(data)\n",
    "    \n",
    "    if min_value == max_value:\n",
    "        return [0.0 for _ in data]\n",
    "    \n",
    "    normalized_data = [(value - min_value) / (max_value - min_value) for value in data]\n",
    "    return normalized_data\n",
    "\n",
    "data = [10, 20, 30, 40, 50]\n",
    "normalized_values = min_max_normalization(data)\n",
    "print(\"Normalized values:\", normalized_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc2671-bb66-40fd-8a87-ed95b2bbc9b3",
   "metadata": {},
   "source": [
    "## 13. Calculate Euclidean Distance Between Two Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e63ee515-29cb-4c33-b6e5-f23f1510c502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance Between Two Points: 5.196152422706632\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import math\n",
    "\n",
    "def euclidean_distance(point1: List[float], point2: List[float]) -> float:\n",
    "    if len(point1) != len(point2):\n",
    "        raise ValueError(\"Points must have the same dimension\")\n",
    "    \n",
    "    squared_diff = [(x - y) ** 2 for x, y in zip(point1, point2)]\n",
    "    \n",
    "    distance = math.sqrt(sum(squared_diff))\n",
    "    \n",
    "    return distance\n",
    "\n",
    "point_a = [1.0, 2.0, 3.0]\n",
    "point_b = [4.0, 5.0, 6.0]\n",
    "print(\"Euclidean Distance Between Two Points:\", euclidean_distance(point_a, point_b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
